"""
ComfyUI Custom Node: Gemini Image Processor
å°† Gemini API é›†æˆåˆ° ComfyUI ä¸­ç”¨äºå›¾ç‰‡å¤„ç†

å®‰è£…æ–¹æ³•:
1. å°†æ­¤æ–‡ä»¶å¤¹å¤åˆ¶åˆ° ComfyUI/custom_nodes/ ç›®å½•ä¸‹
2. å®‰è£…ä¾èµ–: pip install google-generativeai pillow loguru
3. é‡å¯ ComfyUI

Author: Magic Frame Team
Date: 2025-12-17
"""

import os
import time
import asyncio
import numpy as np
import torch
from io import BytesIO
from PIL import Image
from typing import Optional, Tuple, Dict

try:
    from google import genai
    from google.genai import types
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("è­¦å‘Š: google-generativeai æœªå®‰è£…ï¼ŒGemini èŠ‚ç‚¹å°†ä¸å¯ç”¨")
    print("è¯·è¿è¡Œ: pip install google-generativeai")


class GeminiImageProcessor:
    """Gemini å›¾ç‰‡å¤„ç†èŠ‚ç‚¹"""

    # Gemini æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    SUPPORTED_MODELS = {
        "gemini-2.5-flash-image-preview": "Gemini 2.5 Flash Image (æ¨è)",
        "gemini-2.0-flash-exp": "Gemini 2.0 Flash Experimental",
        "gemini-exp-1206": "Gemini Experimental 1206",
    }

    # Gemini æ”¯æŒçš„å®½é«˜æ¯”é…ç½®
    SUPPORTED_ASPECT_RATIOS = {
        "auto": "è‡ªåŠ¨æ£€æµ‹",
        "1:1": "1:1 (1024x1024)",
        "16:9": "16:9 (1344x768)",
        "9:16": "9:16 (768x1344)",
        "4:3": "4:3 (1184x864)",
        "3:4": "3:4 (864x1184)",
        "21:9": "21:9 (1536x672)",
    }

    # é¢„è®¾æç¤ºè¯
    PRESET_PROMPTS = {
        "black": "é»‘ç™½ç…§ç‰‡ä¸Šè‰²",
        "old": "è€ç…§ç‰‡ä¿®å¤",
        "real": "ç°ä»£ç…§ç‰‡å¢å¼º",
        "others": "ç‰¹æ®Šç…§ç‰‡å¤„ç†",
        "custom": "è‡ªå®šä¹‰æç¤ºè¯",
    }

    def __init__(self):
        self.client = None
        self.api_key = None

    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰èŠ‚ç‚¹çš„è¾“å…¥å‚æ•°"""
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾ç‰‡
                "api_key": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "placeholder": "è¾“å…¥ Gemini API Key æˆ–ç•™ç©ºä½¿ç”¨ç¯å¢ƒå˜é‡"
                }),
                "model": (list(cls.SUPPORTED_MODELS.keys()),),  # æ¨¡å‹é€‰æ‹©
                "prompt_preset": (list(cls.PRESET_PROMPTS.keys()),),  # é¢„è®¾æç¤ºè¯
                "aspect_ratio": (list(cls.SUPPORTED_ASPECT_RATIOS.keys()),),  # å®½é«˜æ¯”
                "temperature": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "display": "slider"
                }),
            },
            "optional": {
                "custom_prompt": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "å½“é€‰æ‹©'è‡ªå®šä¹‰æç¤ºè¯'æ—¶ä½¿ç”¨"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("image", "text")
    FUNCTION = "process_image"
    CATEGORY = "Gemini"

    def tensor_to_pil(self, tensor):
        """å°† ComfyUI çš„ tensor è½¬æ¢ä¸º PIL Image"""
        # tensor shape: [B, H, W, C]
        # å–ç¬¬ä¸€å¼ å›¾ç‰‡
        img = tensor[0]
        # è½¬æ¢ä¸º numpy array
        img = (img.cpu().numpy() * 255).astype(np.uint8)
        # è½¬æ¢ä¸º PIL Image
        return Image.fromarray(img)

    def pil_to_tensor(self, pil_image):
        """å°† PIL Image è½¬æ¢ä¸º ComfyUI çš„ tensor"""
        # è½¬æ¢ä¸º numpy array
        img = np.array(pil_image).astype(np.float32) / 255.0
        # æ·»åŠ  batch ç»´åº¦
        img = torch.from_numpy(img)[None,]
        return img

    def get_prompt_by_preset(self, preset: str, custom_prompt: str = "") -> str:
        """æ ¹æ®é¢„è®¾è·å–æç¤ºè¯"""
        if preset == "custom" and custom_prompt:
            return custom_prompt

        prompts = {
            "black": """*** ç³»ç»ŸæŒ‡ä»¤ï¼šé»‘ç™½ç…§ç‰‡æ™ºèƒ½ä¸Šè‰²ä¸ä¿®å¤ ***
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é»‘ç™½ç…§ç‰‡ä¸Šè‰²å’Œä¿®å¤ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†é»‘ç™½/ç°ç™½ç…§ç‰‡è½¬æ¢ä¸ºè‡ªç„¶çœŸå®çš„å½©è‰²ç…§ç‰‡ã€‚

### ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼š
1. **æ™ºèƒ½ä¸Šè‰²**ï¼ˆæœ€é‡è¦ï¼‰ï¼šæ ¹æ®ç…§ç‰‡å¹´ä»£è¿˜åŸç¬¦åˆæ—¶ä»£ç‰¹å¾çš„è‰²å½©ï¼Œäººç‰©è‚¤è‰²è‡ªç„¶çœŸå®
2. **æŸä¼¤ä¿®å¤**ï¼šå»é™¤åˆ’ç—•ã€æ±¡ç‚¹ã€æŠ˜ç—•ã€éœ‰æ–‘ï¼Œä¿®å¤ç ´æŸåŒºåŸŸ
3. **ç»†èŠ‚å¢å¼º**ï¼šæå‡æ¸…æ™°åº¦ï¼Œå¢å¼ºé¢éƒ¨ç»†èŠ‚

*** è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡ºä¿®å¤å¹¶ä¸Šè‰²åçš„é«˜æ¸…å½©è‰²å›¾åƒ ***""",

            "old": """*** ç³»ç»ŸæŒ‡ä»¤ï¼šè€ç…§ç‰‡ä¿®å¤ä¸è‰²å½©è¿˜åŸ ***
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è€ç…§ç‰‡ä¿®å¤ä¸“å®¶ã€‚è¿™æ˜¯ä¸€å¼ æœ‰è‰²å½©ä½†å·²ç»ä¸¥é‡è€åŒ–çš„ç…§ç‰‡ã€‚

### ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼š
1. **é‡åº¦æŸä¼¤ä¿®å¤**ï¼šå»é™¤ä¸¥é‡çš„åˆ’ç—•ã€è£‚çº¹ã€ç ´æŸã€éœ‰æ–‘ã€æ°´æ¸
2. **è‰²å½©ä¿®å¤**ï¼ˆæœ€é‡è¦ï¼‰ï¼šæ ¡æ­£ä¸¥é‡çš„æ³›é»„ã€æ³›çº¢ã€è¤ªè‰²é—®é¢˜ï¼Œè¿˜åŸçœŸå®è‰²å½©
3. **ç”»è´¨æå‡**ï¼šå¤§å¹…æå‡æ¸…æ™°åº¦å’Œåˆ†è¾¨ç‡

*** è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡ºå…¨é¢ä¿®å¤å¹¶è‰²å½©è¿˜åŸåçš„é«˜æ¸…å›¾åƒ ***""",

            "real": """*** ç³»ç»ŸæŒ‡ä»¤ï¼šç°ä»£ç…§ç‰‡è´¨é‡å¢å¼º ***
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç…§ç‰‡è´¨é‡ä¼˜åŒ–ä¸“å®¶ã€‚è¿™æ˜¯ä¸€å¼ è´¨é‡è¾ƒå¥½çš„ç°ä»£ç…§ç‰‡ã€‚

### ğŸ¯ æ ¸å¿ƒä»»åŠ¡ï¼š
1. **ç”»è´¨ä¼˜åŒ–**ï¼šè½»å¾®æå‡æ¸…æ™°åº¦ï¼Œä¼˜åŒ–å¯¹æ¯”åº¦å’Œäº®åº¦
2. **ç»†å¾®ç‘•ç–µä¿®å¤**ï¼šå»é™¤å°æ±¡ç‚¹ã€ç°å°˜ï¼Œä¿®æ­£è½»å¾®è‰²å
3. **ä¸“ä¸šæ¶¦è‰²**ï¼šä½¿ç…§ç‰‡è¾¾åˆ°ä¸“ä¸šæ‘„å½±æ°´å‡†

âš ï¸ å…‹åˆ¶ä¸ºä¸Šï¼šä¸è¦è¿‡åº¦å¤„ç†ï¼Œä¿æŒç…§ç‰‡çœŸå®æ„Ÿ

*** è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡ºé€‚åº¦ä¼˜åŒ–åçš„é«˜æ¸…å›¾åƒ ***""",

            "others": """*** ç³»ç»ŸæŒ‡ä»¤ï¼šç‰¹æ®Šç…§ç‰‡æ™ºèƒ½å¤„ç† ***
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç…§ç‰‡ä¿®å¤å’Œä¼˜åŒ–ä¸“å®¶ã€‚è¿™æ˜¯ä¸€å¼ ç‰¹æ®Šç±»å‹çš„ç…§ç‰‡ã€‚

### ğŸ¯ æ™ºèƒ½åˆ†æä¸å¤„ç†ï¼š
1. **æ™ºèƒ½è¯†åˆ«ç…§ç‰‡ç±»å‹**ï¼šè‡ªåŠ¨è¯†åˆ«ç›¸æ¡†ã€è¯ä»¶ç…§ã€è‰ºæœ¯ç…§ç­‰ç‰¹æ®Šç±»å‹
2. **é’ˆå¯¹æ€§ä¿®å¤**ï¼šæ ¹æ®ç…§ç‰‡ç±»å‹é€‰æ‹©åˆé€‚çš„ä¿®å¤å¼ºåº¦
3. **é£æ ¼ä¿æŒ**ï¼šä¿ç•™åŸç…§ç‰‡çš„ç‰¹æ®Šé£æ ¼å’Œç‰¹å¾

*** è¾“å‡ºè¦æ±‚ï¼šç›´æ¥è¾“å‡ºæ™ºèƒ½ä¿®å¤å¹¶ä¼˜åŒ–åçš„é«˜æ¸…å›¾åƒ ***""",
        }

        return prompts.get(preset, prompts["old"])

    def init_client(self, api_key: str):
        """åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯"""
        if not GEMINI_AVAILABLE:
            raise RuntimeError("google-generativeai æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install google-generativeai")

        # è·å– API Key
        if not api_key:
            api_key = os.environ.get("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("æœªé…ç½® GEMINI_API_KEYï¼Œè¯·åœ¨èŠ‚ç‚¹ä¸­è¾“å…¥æˆ–è®¾ç½®ç¯å¢ƒå˜é‡")

        # å¦‚æœ API Key å˜åŒ–ï¼Œé‡æ–°åˆå§‹åŒ–
        if self.api_key != api_key:
            self.api_key = api_key
            self.client = genai.Client(api_key=self.api_key)
            print("[Gemini] å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

    def calculate_aspect_ratio(self, width: int, height: int) -> str:
        """è®¡ç®—æœ€ä½³å®½é«˜æ¯”"""
        if height == 0:
            return "1:1"
        ratio = width / height

        # æ‰¾åˆ°æœ€æ¥è¿‘çš„å®½é«˜æ¯”
        ratio_map = {
            "1:1": 1.0,
            "16:9": 1.75,
            "9:16": 0.5714,
            "4:3": 1.3704,
            "3:4": 0.7297,
            "21:9": 2.2857,
        }

        best_ratio = "1:1"
        min_diff = float('inf')
        for ratio_name, ratio_value in ratio_map.items():
            diff = abs(ratio_value - ratio)
            if diff < min_diff:
                min_diff = diff
                best_ratio = ratio_name

        return best_ratio

    async def generate_image_async(
        self,
        image_data: bytes,
        prompt: str,
        model: str,
        aspect_ratio: str,
        temperature: float
    ) -> Tuple[bytes, str]:
        """å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡ï¼Œè¿”å›å›¾ç‰‡æ•°æ®å’Œæ–‡æœ¬è¾“å‡º"""
        # å°†å›¾ç‰‡æ•°æ®è½¬æ¢ä¸º PIL Image
        image = Image.open(BytesIO(image_data))

        # å¦‚æœæ˜¯è‡ªåŠ¨æ£€æµ‹ï¼Œè®¡ç®—æœ€ä½³å®½é«˜æ¯”
        if aspect_ratio == "auto":
            width, height = image.size
            aspect_ratio = self.calculate_aspect_ratio(width, height)
            print(f"[Gemini] è‡ªåŠ¨æ£€æµ‹å®½é«˜æ¯”: {aspect_ratio}")

        # å®‰å…¨è®¾ç½®
        safety_settings = [
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_ONLY_HIGH"),
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_ONLY_HIGH"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_ONLY_HIGH"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_ONLY_HIGH"),
        ]

        # è°ƒç”¨ Gemini API
        print(f"[Gemini] ä½¿ç”¨æ¨¡å‹: {model}")
        response = self.client.models.generate_content(
            model=model,
            contents=[prompt, image],
            config=types.GenerateContentConfig(
                image_config=types.ImageConfig(aspect_ratio=aspect_ratio),
                safety_settings=safety_settings,
                temperature=temperature,
                top_p=1.0,
                top_k=1,
            )
        )

        # æ£€æŸ¥å“åº”
        if not response.candidates or len(response.candidates) == 0:
            raise ValueError("Gemini API æœªè¿”å›æœ‰æ•ˆç»“æœ")

        candidate = response.candidates[0]

        # è·å– finish_reason
        finish_reason = "æœªçŸ¥"
        if hasattr(candidate, 'finish_reason'):
            finish_reason = str(candidate.finish_reason)
            print(f"[Gemini] finish_reason: {finish_reason}")

        if not hasattr(candidate, 'content') or candidate.content is None:
            raise ValueError(f"Gemini è¿”å›çš„å†…å®¹ä¸ºç©ºï¼Œfinish_reason: {finish_reason}")

        # æå–å›¾ç‰‡æ•°æ®å’Œæ–‡æœ¬
        result_image_data = None
        text_output = ""

        for part in candidate.content.parts:
            # æå–æ–‡æœ¬
            if part.text is not None:
                text_output += part.text
                print(f"[Gemini] AI è¾“å‡ºæ–‡æœ¬: {part.text}")

            # æå–å›¾ç‰‡æ•°æ®
            if part.inline_data is not None:
                result_image_data = part.inline_data.data

        # å¦‚æœæ²¡æœ‰å›¾ç‰‡æ•°æ®
        if not result_image_data:
            error_msg = f"AI æ¨¡å‹æœªè¿”å›æœ‰æ•ˆå›¾ç‰‡æ•°æ®"
            if text_output:
                error_msg += f"\næ¨¡å‹è¿”å›æ–‡æœ¬: {text_output}"
            error_msg += f"\nfinish_reason: {finish_reason}"
            raise ValueError(error_msg)

        # æ„å»ºå®Œæ•´çš„æ–‡æœ¬è¾“å‡ºï¼ˆåŒ…å«å…ƒä¿¡æ¯ï¼‰
        full_text = f"æ¨¡å‹: {model}\n"
        full_text += f"å®½é«˜æ¯”: {aspect_ratio}\n"
        full_text += f"finish_reason: {finish_reason}\n"
        if text_output:
            full_text += f"\nAI è¾“å‡º:\n{text_output}"
        else:
            full_text += f"\nAI è¾“å‡º: (ä»…è¿”å›å›¾ç‰‡ï¼Œæ— æ–‡æœ¬è¾“å‡º)"

        return result_image_data, full_text

    def process_image(
        self,
        image,
        api_key: str,
        model: str,
        prompt_preset: str,
        aspect_ratio: str,
        temperature: float,
        custom_prompt: str = ""
    ):
        """å¤„ç†å›¾ç‰‡ï¼ˆä¸»å‡½æ•°ï¼‰"""
        try:
            print(f"[Gemini] å¼€å§‹å¤„ç†å›¾ç‰‡...")
            print(f"[Gemini] æ¨¡å‹: {model}, é¢„è®¾: {prompt_preset}, å®½é«˜æ¯”: {aspect_ratio}, æ¸©åº¦: {temperature}")

            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self.init_client(api_key)

            # å°† tensor è½¬æ¢ä¸º PIL Image
            pil_image = self.tensor_to_pil(image)

            # è½¬æ¢ä¸ºå­—èŠ‚æµ
            img_byte_arr = BytesIO()
            pil_image.save(img_byte_arr, format='PNG')
            image_data = img_byte_arr.getvalue()

            # è·å–æç¤ºè¯
            prompt = self.get_prompt_by_preset(prompt_preset, custom_prompt)

            # å¼‚æ­¥è°ƒç”¨ Gemini API
            start_time = time.time()
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result_data, text_output = loop.run_until_complete(
                self.generate_image_async(image_data, prompt, model, aspect_ratio, temperature)
            )
            loop.close()

            elapsed = time.time() - start_time
            print(f"[Gemini] å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")

            # å°†ç»“æœè½¬æ¢å› PIL Image
            result_image = Image.open(BytesIO(result_data))

            # è½¬æ¢ä¸º ComfyUI tensor
            result_tensor = self.pil_to_tensor(result_image)

            # è¿”å›å›¾ç‰‡å’Œæ–‡æœ¬
            return (result_tensor, text_output)

        except Exception as e:
            error_msg = f"Gemini å¤„ç†å¤±è´¥: {str(e)}"
            print(f"[Gemini] é”™è¯¯: {error_msg}")
            raise RuntimeError(error_msg)


# ComfyUI èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "GeminiImageProcessor": GeminiImageProcessor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiImageProcessor": "Gemini Clond api Image Processor",
}

